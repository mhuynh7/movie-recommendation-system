{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procure and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit\n",
      "  Downloading implicit-0.7.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/madelinehuynh/anaconda3/lib/python3.11/site-packages (from implicit) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.16 in /Users/madelinehuynh/anaconda3/lib/python3.11/site-packages (from implicit) (1.11.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/madelinehuynh/anaconda3/lib/python3.11/site-packages (from implicit) (4.65.0)\n",
      "Requirement already satisfied: threadpoolctl in /Users/madelinehuynh/anaconda3/lib/python3.11/site-packages (from implicit) (2.2.0)\n",
      "Downloading implicit-0.7.2-cp311-cp311-macosx_10_9_x86_64.whl (811 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: implicit\n",
      "Successfully installed implicit-0.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import ast\n",
    "import warnings\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1425941529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1425942435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>858</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1425941523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1221</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1425941546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1246</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1425941556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      110     1.0  1425941529\n",
       "1       1      147     4.5  1425942435\n",
       "2       1      858     5.0  1425941523\n",
       "3       1     1221     5.0  1425941546\n",
       "4       1     1246     5.0  1425941556"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('/Users/madelinehuynh/Downloads/ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_metadata = pd.read_csv('/Users/madelinehuynh/Downloads/movies_metadata.csv')\n",
    "movies_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           keywords\n",
       "0    862  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...\n",
       "1   8844  [{'id': 10090, 'name': 'board game'}, {'id': 1...\n",
       "2  15602  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...\n",
       "3  31357  [{'id': 818, 'name': 'based on novel'}, {'id':...\n",
       "4  11862  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = pd.read_csv('/Users/madelinehuynh/Downloads/keywords.csv')\n",
    "keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>15602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
       "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
       "      <td>31357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>11862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                cast  \\\n",
       "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "2  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
       "3  [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
       "4  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
       "\n",
       "                                                crew     id  \n",
       "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...    862  \n",
       "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   8844  \n",
       "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...  15602  \n",
       "3  [{'credit_id': '52fe44779251416c91011acb', 'de...  31357  \n",
       "4  [{'credit_id': '52fe44959251416c75039ed7', 'de...  11862  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credits = pd.read_csv('/Users/madelinehuynh/Downloads/credits.csv')\n",
    "credits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in ratings dataset\n",
    "print('ratings', ratings.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies metadata adult                        0\n",
      "belongs_to_collection    40972\n",
      "budget                       0\n",
      "genres                       0\n",
      "homepage                 37684\n",
      "id                           0\n",
      "imdb_id                     17\n",
      "original_language           11\n",
      "original_title               0\n",
      "overview                   954\n",
      "popularity                   5\n",
      "poster_path                386\n",
      "production_companies         3\n",
      "production_countries         3\n",
      "release_date                87\n",
      "revenue                      6\n",
      "runtime                    263\n",
      "spoken_languages             6\n",
      "status                      87\n",
      "tagline                  25054\n",
      "title                        6\n",
      "video                        6\n",
      "vote_average                 6\n",
      "vote_count                   6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in movies_metadata dataset\n",
    "print('movies metadata', movies_metadata.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keywords id          0\n",
      "keywords    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in keywords dataset\n",
    "print('keywords', keywords.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credits cast    0\n",
      "crew    0\n",
      "id      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in credits dataset\n",
    "print('credits', credits.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the movies metadata dataset has noticeable amount of NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45466\n"
     ]
    }
   ],
   "source": [
    "# check length of movies metadata set\n",
    "print(len(movies_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>release_date</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>revenue</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>30000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>65000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>11.7129</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>16000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               original_title  \\\n",
       "0    862                    Toy Story   \n",
       "1   8844                      Jumanji   \n",
       "2  15602             Grumpier Old Men   \n",
       "3  31357            Waiting to Exhale   \n",
       "4  11862  Father of the Bride Part II   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                                            overview release_date popularity  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   1995-10-30  21.946943   \n",
       "1  When siblings Judy and Peter discover an encha...   1995-12-15  17.015539   \n",
       "2  A family wedding reignites the ancient feud be...   1995-12-22    11.7129   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   1995-12-22   3.859495   \n",
       "4  Just when George Banks has recovered from his ...   1995-02-10   8.387519   \n",
       "\n",
       "   vote_average  vote_count      revenue    budget  \n",
       "0           7.7      5415.0  373554033.0  30000000  \n",
       "1           6.9      2413.0  262797249.0  65000000  \n",
       "2           6.5        92.0          0.0         0  \n",
       "3           6.1        34.0   81452156.0  16000000  \n",
       "4           5.7       173.0   76578911.0         0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select relevant columns for recommender model\n",
    "selected_columns = ['id', 'original_title', 'genres', 'overview', 'release_date', 'popularity', 'vote_average', 'vote_count', 'revenue', 'budget']\n",
    "movies_metadata_subset = movies_metadata[selected_columns]\n",
    "movies_metadata_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "original_title      0\n",
       "genres              0\n",
       "overview          954\n",
       "release_date       87\n",
       "popularity          5\n",
       "vote_average        6\n",
       "vote_count          6\n",
       "revenue             6\n",
       "budget              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_metadata_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 object\n",
       "original_title     object\n",
       "genres             object\n",
       "overview           object\n",
       "release_date       object\n",
       "popularity         object\n",
       "vote_average      float64\n",
       "vote_count        float64\n",
       "revenue           float64\n",
       "budget             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_metadata_subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                0\n",
      "original_title    0\n",
      "genres            0\n",
      "overview          0\n",
      "release_date      0\n",
      "popularity        0\n",
      "vote_average      0\n",
      "vote_count        0\n",
      "revenue           0\n",
      "budget            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert 'release_date' column to datetime objects\n",
    "movies_metadata_subset['release_date'] = pd.to_datetime(movies_metadata_subset['release_date'], errors = 'coerce')\n",
    "\n",
    "# Convert 'popularity' column to numeric datatype\n",
    "movies_metadata_subset['popularity'] = pd.to_numeric(movies_metadata_subset['popularity'], errors = 'coerce')\n",
    "\n",
    "# Perform mean imputation for numerical columns\n",
    "numerical_columns = [\"popularity\", \"vote_average\", \"vote_count\", \"revenue\"]\n",
    "movies_metadata_subset[numerical_columns] = movies_metadata_subset[numerical_columns].fillna(movies_metadata_subset[numerical_columns].mean())\n",
    "\n",
    "# Mode imputation for categorical columns\n",
    "categorical_columns = [\"release_date\"]\n",
    "for col in categorical_columns:\n",
    "    movies_metadata_subset[col] = movies_metadata_subset[col].fillna(movies_metadata_subset[col].mode()[0])\n",
    "\n",
    "# Fill NAs for overview description with not available\n",
    "movies_metadata_subset['overview'] = movies_metadata_subset['overview'].fillna('Not available')\n",
    "\n",
    "# Print the result\n",
    "print(movies_metadata_subset.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating                     timestamp\n",
      "0       1      110     1.0 1970-01-01 00:00:01.425941529\n",
      "1       1      147     4.5 1970-01-01 00:00:01.425942435\n",
      "2       1      858     5.0 1970-01-01 00:00:01.425941523\n",
      "3       1     1221     5.0 1970-01-01 00:00:01.425941546\n",
      "4       1     1246     5.0 1970-01-01 00:00:01.425941556\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp to datetime \n",
    "# Convert the 'timestamp' column to datetime format\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id                                           keywords\n",
      "0    862  [jealousy, toy, boy, friendship, friends, riva...\n",
      "1   8844  [board game, disappearance, based on children'...\n",
      "2  15602  [fishing, best friend, duringcreditsstinger, o...\n",
      "3  31357  [based on novel, interracial relationship, sin...\n",
      "4  11862  [baby, midlife crisis, confidence, aging, daug...\n"
     ]
    }
   ],
   "source": [
    "# Parse the 'keywords' column to extract keywords\n",
    "keywords['keywords'] = keywords['keywords'].apply(lambda x: [item['name'] for item in ast.literal_eval(x)])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(keywords.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                cast  \\\n",
      "0  [Tom Hanks, Tim Allen, Don Rickles, Jim Varney...   \n",
      "1  [Robin Williams, Jonathan Hyde, Kirsten Dunst,...   \n",
      "2  [Walter Matthau, Jack Lemmon, Ann-Margret, Sop...   \n",
      "3  [Whitney Houston, Angela Bassett, Loretta Devi...   \n",
      "4  [Steve Martin, Diane Keaton, Martin Short, Kim...   \n",
      "\n",
      "                                                crew     id  \n",
      "0  [John Lasseter, Joss Whedon, Andrew Stanton, J...    862  \n",
      "1  [Larry J. Franco, Jonathan Hensleigh, James Ho...   8844  \n",
      "2  [Howard Deutch, Mark Steven Johnson, Mark Stev...  15602  \n",
      "3  [Forest Whitaker, Ronald Bass, Ronald Bass, Ez...  31357  \n",
      "4  [Alan Silvestri, Elliot Davis, Nancy Meyers, N...  11862  \n"
     ]
    }
   ],
   "source": [
    "# Parse the 'cast' column to extract cast information\n",
    "credits['cast'] = credits['cast'].apply(lambda x: [item['name'] for item in ast.literal_eval(x)])\n",
    "\n",
    "# Parse the 'crew' column to extract crew information\n",
    "credits['crew'] = credits['crew'].apply(lambda x: [item['name'] for item in ast.literal_eval(x)])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(credits.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        object\n",
       "original_title            object\n",
       "genres                    object\n",
       "overview                  object\n",
       "release_date      datetime64[ns]\n",
       "popularity               float64\n",
       "vote_average             float64\n",
       "vote_count               float64\n",
       "revenue                  float64\n",
       "budget                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_metadata_subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_subset['budget'] = pd.to_numeric(movies_metadata_subset['budget'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new feature 'profit' by subtracting 'budget' from 'revenue'\n",
    "movies_metadata_subset['profit'] = movies_metadata_subset['revenue'] - movies_metadata_subset['budget']\n",
    "\n",
    "# Add a new feature 'profit_margin' by dividing 'profit' by 'revenue'\n",
    "movies_metadata_subset['profit_margin'] = movies_metadata_subset['profit'] / movies_metadata_subset['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of keywords for keywords data, get the number of cast and crew for credits data\n",
    "\n",
    "# Feature engineering transformation for keywords\n",
    "keywords['num_keywords'] = keywords['keywords'].apply(lambda x: len(x))\n",
    "\n",
    "# Feature engineering transformation for credits\n",
    "credits['num_cast'] = credits['cast'].apply(lambda x: len(x))\n",
    "credits['num_crew'] = credits['crew'].apply(lambda x: len(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'id' columns are integers\n",
    "def clean_id_column(df, column_name):\n",
    "    df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n",
    "    df.dropna(subset=[column_name], inplace=True)\n",
    "    df[column_name] = df[column_name].astype(int)\n",
    "\n",
    "# Clean 'id' columns in all datasets\n",
    "clean_id_column(movies_metadata_subset, 'id')\n",
    "clean_id_column(keywords, 'id')\n",
    "clean_id_column(credits, 'id')\n",
    "\n",
    "# Merge datasets (movies_metadata, keywords, credits)\n",
    "combined_data = pd.merge(movies_metadata_subset, keywords, on='id', how='left')\n",
    "combined_data = pd.merge(combined_data, credits, on='id', how='left')\n",
    "\n",
    "# Convert 'release_date' to datetime and extract year, month, and day\n",
    "combined_data['release_date'] = pd.to_datetime(combined_data['release_date'], errors='coerce')\n",
    "combined_data['release_year'] = combined_data['release_date'].dt.year.fillna(0).astype(int)\n",
    "combined_data['release_month'] = combined_data['release_date'].dt.month.fillna(0).astype(int)\n",
    "combined_data['release_day'] = combined_data['release_date'].dt.day.fillna(0).astype(int)\n",
    "\n",
    "# Convert 'budget' and 'popularity' to numeric\n",
    "combined_data['budget'] = pd.to_numeric(combined_data['budget'], errors='coerce').fillna(0)\n",
    "combined_data['popularity'] = pd.to_numeric(combined_data['popularity'], errors='coerce').fillna(0)\n",
    "\n",
    "# Encode genres\n",
    "def parse_genres(x):\n",
    "    try:\n",
    "        return ', '.join([d['name'] for d in literal_eval(x)])\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return ''\n",
    "\n",
    "combined_data['genres'] = combined_data['genres'].apply(parse_genres)\n",
    "combined_data['genres_encoded'] = combined_data['genres'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>overview</th>\n",
       "      <th>release_date</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>revenue</th>\n",
       "      <th>budget</th>\n",
       "      <th>...</th>\n",
       "      <th>keywords</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>num_cast</th>\n",
       "      <th>num_crew</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_day</th>\n",
       "      <th>genres_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Animation, Comedy, Family</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[jealousy, toy, boy, friendship, friends, riva...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[Tom Hanks, Tim Allen, Don Rickles, Jim Varney...</td>\n",
       "      <td>[John Lasseter, Joss Whedon, Andrew Stanton, J...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Adventure, Fantasy, Family</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>65000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[board game, disappearance, based on children'...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[Robin Williams, Jonathan Hyde, Kirsten Dunst,...</td>\n",
       "      <td>[Larry J. Franco, Jonathan Hensleigh, James Ho...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Romance, Comedy</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>11.712900</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[fishing, best friend, duringcreditsstinger, o...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Walter Matthau, Jack Lemmon, Ann-Margret, Sop...</td>\n",
       "      <td>[Howard Deutch, Mark Steven Johnson, Mark Stev...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>3294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>3.859495</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[based on novel, interracial relationship, sin...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Whitney Houston, Angela Bassett, Loretta Devi...</td>\n",
       "      <td>[Forest Whitaker, Ronald Bass, Ronald Bass, Ez...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>1388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>[baby, midlife crisis, confidence, aging, daug...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[Steve Martin, Diane Keaton, Martin Short, Kim...</td>\n",
       "      <td>[Alan Silvestri, Elliot Davis, Nancy Meyers, N...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               original_title                      genres  \\\n",
       "0    862                    Toy Story   Animation, Comedy, Family   \n",
       "1   8844                      Jumanji  Adventure, Fantasy, Family   \n",
       "2  15602             Grumpier Old Men             Romance, Comedy   \n",
       "3  31357            Waiting to Exhale      Comedy, Drama, Romance   \n",
       "4  11862  Father of the Bride Part II                      Comedy   \n",
       "\n",
       "                                            overview release_date  popularity  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...   1995-10-30   21.946943   \n",
       "1  When siblings Judy and Peter discover an encha...   1995-12-15   17.015539   \n",
       "2  A family wedding reignites the ancient feud be...   1995-12-22   11.712900   \n",
       "3  Cheated on, mistreated and stepped on, the wom...   1995-12-22    3.859495   \n",
       "4  Just when George Banks has recovered from his ...   1995-02-10    8.387519   \n",
       "\n",
       "   vote_average  vote_count      revenue      budget  ...  \\\n",
       "0           7.7      5415.0  373554033.0  30000000.0  ...   \n",
       "1           6.9      2413.0  262797249.0  65000000.0  ...   \n",
       "2           6.5        92.0          0.0         0.0  ...   \n",
       "3           6.1        34.0   81452156.0  16000000.0  ...   \n",
       "4           5.7       173.0   76578911.0         0.0  ...   \n",
       "\n",
       "                                            keywords  num_keywords  \\\n",
       "0  [jealousy, toy, boy, friendship, friends, riva...           9.0   \n",
       "1  [board game, disappearance, based on children'...           6.0   \n",
       "2  [fishing, best friend, duringcreditsstinger, o...           4.0   \n",
       "3  [based on novel, interracial relationship, sin...           5.0   \n",
       "4  [baby, midlife crisis, confidence, aging, daug...           9.0   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [Tom Hanks, Tim Allen, Don Rickles, Jim Varney...   \n",
       "1  [Robin Williams, Jonathan Hyde, Kirsten Dunst,...   \n",
       "2  [Walter Matthau, Jack Lemmon, Ann-Margret, Sop...   \n",
       "3  [Whitney Houston, Angela Bassett, Loretta Devi...   \n",
       "4  [Steve Martin, Diane Keaton, Martin Short, Kim...   \n",
       "\n",
       "                                                crew num_cast num_crew  \\\n",
       "0  [John Lasseter, Joss Whedon, Andrew Stanton, J...     13.0    106.0   \n",
       "1  [Larry J. Franco, Jonathan Hensleigh, James Ho...     26.0     16.0   \n",
       "2  [Howard Deutch, Mark Steven Johnson, Mark Stev...      7.0      4.0   \n",
       "3  [Forest Whitaker, Ronald Bass, Ronald Bass, Ez...     10.0     10.0   \n",
       "4  [Alan Silvestri, Elliot Davis, Nancy Meyers, N...     12.0      7.0   \n",
       "\n",
       "   release_year  release_month  release_day  genres_encoded  \n",
       "0          1995             10           30            1079  \n",
       "1          1995             12           15             943  \n",
       "2          1995             12           22            3294  \n",
       "3          1995             12           22            1388  \n",
       "4          1995              2           10            1229  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'original_title', 'genres', 'overview', 'release_date',\n",
       "       'popularity', 'vote_average', 'vote_count', 'revenue', 'budget',\n",
       "       'profit', 'profit_margin', 'keywords', 'num_keywords', 'cast', 'crew',\n",
       "       'num_cast', 'num_crew', 'release_year', 'release_month', 'release_day',\n",
       "       'genres_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         int64\n",
       "original_title            object\n",
       "genres                    object\n",
       "overview                  object\n",
       "release_date      datetime64[ns]\n",
       "popularity               float64\n",
       "vote_average             float64\n",
       "vote_count               float64\n",
       "revenue                  float64\n",
       "budget                   float64\n",
       "profit                   float64\n",
       "profit_margin            float64\n",
       "keywords                  object\n",
       "num_keywords             float64\n",
       "cast                      object\n",
       "crew                      object\n",
       "num_cast                 float64\n",
       "num_crew                 float64\n",
       "release_year               int64\n",
       "release_month              int64\n",
       "release_day                int64\n",
       "genres_encoded             int16\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposed Model #1: content based filtering based on textual similarities (overview, genre, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15444                                    Toy Story 3\n",
      "3012                                     Toy Story 2\n",
      "1823                                  Small Soldiers\n",
      "24671                                      Small Fry\n",
      "25849    Silent Night, Deadly Night 5: The Toy Maker\n",
      "37875                                          玩具修理者\n",
      "10349                         The 40 Year Old Virgin\n",
      "7593                                           Dolls\n",
      "2154                                            Toys\n",
      "1896                                  Child's Play 3\n",
      "Name: original_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['revenue', 'budget', 'popularity', 'vote_average', 'vote_count', 'num_cast', 'num_keywords']\n",
    "combined_data[numerical_features] = scaler.fit_transform(combined_data[numerical_features])\n",
    "\n",
    "# Combine text features\n",
    "combined_data['combined_features'] = combined_data['overview'].fillna('') + \" \" + combined_data['genres'] + \" \" + combined_data['keywords'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "# Vectorize text data\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(combined_data['combined_features'])\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get movie recommendations\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    idx = combined_data[combined_data['original_title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return combined_data['original_title'].iloc[movie_indices]\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations('Toy Story'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13864            The Taking of Pelham 1 2 3\n",
      "8653                           The Incident\n",
      "3280     The Taking of Pelham One Two Three\n",
      "45894                       New York Subway\n",
      "19528                            Stag Night\n",
      "13537                   Adrift in Manhattan\n",
      "334                 While You Were Sleeping\n",
      "12152                      We Own the Night\n",
      "11751                                  TMNT\n",
      "41647                              Marathon\n",
      "Name: original_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(get_recommendations('Money Train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Story 3: 0.5042\n",
      "Toy Story 2: 0.4810\n",
      "Small Soldiers: 0.2875\n",
      "Small Fry: 0.2788\n",
      "Silent Night, Deadly Night 5: The Toy Maker: 0.2716\n",
      "玩具修理者: 0.2668\n",
      "The 40 Year Old Virgin: 0.2430\n",
      "Dolls: 0.2255\n",
      "Toys: 0.2193\n",
      "Child's Play 3: 0.2168\n"
     ]
    }
   ],
   "source": [
    "# Function to get movie recommendations with similarity scores\n",
    "def get_recommendations_with_scores(title, combined_data):\n",
    "    if title not in combined_data['original_title'].values:\n",
    "        return f\"Movie '{title}' not found in the dataset.\"\n",
    "    \n",
    "    idx = combined_data[combined_data['original_title'] == title].index[0]\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(combined_data['combined_features'])\n",
    "\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()\n",
    "    sim_scores = sorted(list(enumerate(cosine_sim)), key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]  # Exclude the movie itself\n",
    "    \n",
    "    recommendations = [(combined_data['original_title'].iloc[i[0]], i[1]) for i in sim_scores]\n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "recommendations_with_scores = get_recommendations_with_scores('Toy Story', combined_data)\n",
    "for movie, score in recommendations_with_scores:\n",
    "    print(f\"{movie}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Taking of Pelham 1 2 3: 0.4894\n",
      "The Incident: 0.4214\n",
      "The Taking of Pelham One Two Three: 0.3911\n",
      "New York Subway: 0.3394\n",
      "Stag Night: 0.3295\n",
      "Adrift in Manhattan: 0.2907\n",
      "While You Were Sleeping: 0.2792\n",
      "We Own the Night: 0.2646\n",
      "TMNT: 0.2564\n",
      "Marathon: 0.2491\n"
     ]
    }
   ],
   "source": [
    "recommendations_with_scores = get_recommendations_with_scores('Money Train', combined_data)\n",
    "for movie, score in recommendations_with_scores:\n",
    "    print(f\"{movie}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposed Model #2: collaborative filtering using ratings for each movie id (user item interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId                int64\n",
       "movieId               int64\n",
       "rating              float64\n",
       "timestamp    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled combined_data shape: (1000, 23)\n",
      "Sampled ratings shape: (925598, 4)\n"
     ]
    }
   ],
   "source": [
    "# Take the first X entries from combined_data\n",
    "sample_combined_data = combined_data.head(1000)\n",
    "\n",
    "# Ensure the ratings dataset only includes ratings for the sampled movies\n",
    "sample_movie_ids = sample_combined_data['id'].tolist()\n",
    "sample_ratings = ratings[ratings['movieId'].isin(sample_movie_ids)]\n",
    "\n",
    "# Check for duplicates (if any)\n",
    "sample_ratings.drop_duplicates(subset=['userId', 'movieId'], inplace=True)\n",
    "\n",
    "# Print the shapes of the sampled datasets to verify\n",
    "print(\"Sampled combined_data shape:\", sample_combined_data.shape)\n",
    "print(\"Sampled ratings shape:\", sample_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative Filtering Recommendations:\n",
      "Pocahontas: 0.4528\n",
      "Just Cause: 0.4513\n",
      "A Kid in King Arthur's Court: 0.4513\n",
      "Mi Vida Loca: 0.4511\n",
      "Kiss of Death: 0.4504\n",
      "Legends of the Fall: 0.4503\n",
      "Love Affair: 0.4501\n",
      "Little Women: 0.4501\n",
      "L'Enfer: 0.4500\n",
      "Star Wars: 0.4498\n"
     ]
    }
   ],
   "source": [
    "# Create the user-item matrix for the sampled ratings\n",
    "ratings_matrix = sample_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "# Fill missing values with 0 (assuming missing values mean the user hasn't rated the movie)\n",
    "ratings_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# Normalize ratings by subtracting the mean rating of each user\n",
    "ratings_matrix_normalized = ratings_matrix.sub(ratings_matrix.mean(axis=1), axis=0)\n",
    "\n",
    "# Convert the normalized ratings matrix to a sparse matrix\n",
    "ratings_sparse_matrix = csr_matrix(ratings_matrix_normalized.values)\n",
    "\n",
    "# Function to compute cosine similarity in batches\n",
    "def compute_cosine_similarity_in_batches(matrix, batch_size=1000):\n",
    "    n_items = matrix.shape[1]\n",
    "    sim_matrix = np.zeros((n_items, n_items))\n",
    "\n",
    "    for start in range(0, n_items, batch_size):\n",
    "        end = min(start + batch_size, n_items)\n",
    "        batch_matrix = matrix[:, start:end]\n",
    "        batch_sim_matrix = cosine_similarity(batch_matrix.T)\n",
    "        sim_matrix[start:end, :] = batch_sim_matrix\n",
    "\n",
    "    return sim_matrix\n",
    "\n",
    "# Compute cosine similarity in batches for the sampled data\n",
    "cosine_sim_ratings = compute_cosine_similarity_in_batches(ratings_sparse_matrix)\n",
    "\n",
    "# Function to get collaborative filtering movie recommendations based on ratings\n",
    "def get_collaborative_recommendations(title, combined_data=sample_combined_data, cosine_sim_ratings=cosine_sim_ratings):\n",
    "    if title not in combined_data['original_title'].values:\n",
    "        return f\"Movie '{title}' not found in the sampled data.\"\n",
    "    \n",
    "    movie_id = combined_data[combined_data['original_title'] == title]['id'].values[0]\n",
    "    idx = ratings_matrix.columns.get_loc(movie_id)\n",
    "    sim_scores = list(enumerate(cosine_sim_ratings[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]  # Exclude the movie itself\n",
    "    \n",
    "    recommendations = [(combined_data['original_title'].iloc[i[0]], i[1]) for i in sim_scores]\n",
    "    return recommendations\n",
    "\n",
    "# Example usage for collaborative filtering recommendations on the sampled data\n",
    "collaborative_recommendations = get_collaborative_recommendations('Toy Story')\n",
    "\n",
    "print(\"Collaborative Filtering Recommendations:\")\n",
    "for movie, score in collaborative_recommendations:\n",
    "    print(f\"{movie}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proposed Model #3: hybrid approach (content based and collaborative filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Recommendations:\n",
      "Heat: 0.1763\n",
      "Dunston Checks In: 0.1478\n",
      "The Indian in the Cupboard: 0.1078\n",
      "Grumpier Old Men: 0.1058\n",
      "Othello: 0.0966\n",
      "Jumanji: 0.0960\n",
      "From Dusk Till Dawn: 0.0875\n",
      "Dangerous Minds: 0.0666\n",
      "Twelve Monkeys: 0.0665\n",
      "Four Rooms: 0.0637\n"
     ]
    }
   ],
   "source": [
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['revenue', 'budget', 'popularity', 'vote_average', 'vote_count', 'num_cast', 'num_keywords']\n",
    "sample_combined_data[numerical_features] = scaler.fit_transform(sample_combined_data[numerical_features])\n",
    "\n",
    "# Combine text features\n",
    "sample_combined_data['combined_features'] = sample_combined_data['overview'].fillna('') + \" \" + sample_combined_data['genres'] + \" \" + sample_combined_data['keywords'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "# Vectorize text data\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(sample_combined_data['combined_features'])\n",
    "\n",
    "# Compute the cosine similarity matrix for content-based filtering\n",
    "cosine_sim_content = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Create the user-item matrix for the sampled ratings\n",
    "ratings_matrix = sample_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "ratings_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# Normalize ratings by subtracting the mean rating of each user\n",
    "ratings_matrix_normalized = ratings_matrix.sub(ratings_matrix.mean(axis=1), axis=0)\n",
    "\n",
    "# Convert the normalized ratings matrix to a sparse matrix\n",
    "ratings_sparse_matrix = csr_matrix(ratings_matrix_normalized.values)\n",
    "\n",
    "def compute_cosine_similarity_in_batches(matrix, batch_size=100):\n",
    "    n_items = matrix.shape[1]\n",
    "    sim_matrix = np.zeros((n_items, n_items))\n",
    "\n",
    "    for start in range(0, n_items, batch_size):\n",
    "        end = min(start + batch_size, n_items)\n",
    "        batch_matrix = matrix[:, start:end]\n",
    "        batch_sim_matrix = cosine_similarity(batch_matrix.T)\n",
    "        \n",
    "        sim_matrix[start:end, start:end] = batch_sim_matrix\n",
    "\n",
    "        for inner_start in range(0, start, batch_size):\n",
    "            inner_end = min(inner_start + batch_size, n_items)\n",
    "            inner_batch_matrix = matrix[:, inner_start:inner_end]\n",
    "            cross_sim_matrix = cosine_similarity(batch_matrix.T, inner_batch_matrix.T)\n",
    "            sim_matrix[start:end, inner_start:inner_end] = cross_sim_matrix\n",
    "            sim_matrix[inner_start:inner_end, start:end] = cross_sim_matrix.T\n",
    "\n",
    "    return sim_matrix\n",
    "\n",
    "# Compute cosine similarity in batches for the sampled data\n",
    "cosine_sim_ratings = compute_cosine_similarity_in_batches(ratings_sparse_matrix)\n",
    "\n",
    "# Ensure the dimensions of cosine similarity matrices match\n",
    "min_dim = min(cosine_sim_content.shape[0], ratings_matrix.shape[1])\n",
    "cosine_sim_content = cosine_sim_content[:min_dim, :min_dim]\n",
    "cosine_sim_ratings = cosine_sim_ratings[:min_dim, :min_dim]\n",
    "\n",
    "# Normalize the similarity matrices\n",
    "cosine_sim_content_normalized = cosine_sim_content / np.max(cosine_sim_content)\n",
    "cosine_sim_ratings_normalized = cosine_sim_ratings / np.max(cosine_sim_ratings)\n",
    "\n",
    "alpha = 0.5  # Weight for content-based filtering\n",
    "beta = 1 - alpha  # Weight for collaborative filtering\n",
    "\n",
    "combined_sim = alpha * cosine_sim_content_normalized + beta * cosine_sim_ratings_normalized\n",
    "\n",
    "# Function to get hybrid recommendations\n",
    "def get_hybrid_recommendations(title, combined_data=sample_combined_data, combined_sim=combined_sim):\n",
    "    if title not in combined_data['original_title'].values:\n",
    "        return f\"Movie '{title}' not found in the data.\"\n",
    "    \n",
    "    idx = combined_data[combined_data['original_title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(combined_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]  # Exclude the movie itself\n",
    "    \n",
    "    recommendations = [(combined_data['original_title'].iloc[i[0]], i[1]) for i in sim_scores]\n",
    "    return recommendations\n",
    "\n",
    "# Example usage for hybrid recommendations on the data\n",
    "hybrid_recommendations = get_hybrid_recommendations('Toy Story')\n",
    "\n",
    "print(\"Hybrid Recommendations:\")\n",
    "for movie, score in hybrid_recommendations:\n",
    "    print(f\"{movie}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting/Overfitting Checks w/ Proposed Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.7860080135576667\n",
      "Mean Absolute Error: 0.6454377999287542\n"
     ]
    }
   ],
   "source": [
    "#for content based filtering\n",
    "# Reduce data size for testing\n",
    "sample_size = 20000\n",
    "sample_combined_data = combined_data.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = train_test_split(sample_combined_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize text data for training set\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix_train = tfidf.fit_transform(train_data['combined_features'])\n",
    "\n",
    "# Compute cosine similarity matrix for training set in chunks\n",
    "def compute_cosine_similarity_in_chunks(matrix, chunk_size=100):\n",
    "    n = matrix.shape[0]\n",
    "    cosine_sim_matrix = np.zeros((n, n))\n",
    "    for start in range(0, n, chunk_size):\n",
    "        end = min(start + chunk_size, n)\n",
    "        chunk_sim = cosine_similarity(matrix[start:end], matrix)\n",
    "        cosine_sim_matrix[start:end] = chunk_sim\n",
    "    return cosine_sim_matrix\n",
    "\n",
    "cosine_sim_train = compute_cosine_similarity_in_chunks(tfidf_matrix_train)\n",
    "\n",
    "# Function to get movie recommendations\n",
    "def get_recommendations(title, combined_data=train_data, cosine_sim=cosine_sim_train, top_n=10):\n",
    "    try:\n",
    "        idx = combined_data[combined_data['original_title'] == title].index[0]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:top_n + 1]\n",
    "        movie_indices = [i[0] for i in sim_scores]\n",
    "        return combined_data['original_title'].iloc[movie_indices]\n",
    "    except IndexError:\n",
    "        return []\n",
    "\n",
    "# Evaluate on test set in batches\n",
    "def evaluate_model(test_data, combined_data=train_data, cosine_sim=cosine_sim_train, batch_size=100):\n",
    "    predictions = []\n",
    "    n = len(test_data)\n",
    "    \n",
    "    for start in range(0, n, batch_size):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = test_data.iloc[start:end]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            title = row['original_title']\n",
    "            true_ratings = test_data[test_data['original_title'] == title]['vote_average'].values\n",
    "            pred_titles = get_recommendations(title)\n",
    "            if len(pred_titles) == 0:\n",
    "                continue\n",
    "            pred_ratings = train_data[train_data['original_title'].isin(pred_titles)]['vote_average'].values\n",
    "            if len(pred_ratings) == 0:\n",
    "                continue\n",
    "            predictions.append((true_ratings.mean(), pred_ratings.mean()))\n",
    "    \n",
    "    if not predictions:\n",
    "        return float('nan'), float('nan')\n",
    "    \n",
    "    true_values, pred_values = zip(*predictions)\n",
    "    return mean_squared_error(true_values, pred_values), mean_absolute_error(true_values, pred_values)\n",
    "\n",
    "mse, mae = evaluate_model(test_data)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Training): 0.7517367636940092\n",
      "Mean Absolute Error (Training): 0.6620983245054448\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_train(train_data, combined_data=train_data, cosine_sim=cosine_sim_train, batch_size=100):\n",
    "    predictions = []\n",
    "    n = len(train_data)\n",
    "    \n",
    "    for start in range(0, n, batch_size):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch = train_data.iloc[start:end]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            title = row['original_title']\n",
    "            true_ratings = train_data[train_data['original_title'] == title]['vote_average'].values\n",
    "            pred_titles = get_recommendations(title)\n",
    "            if len(pred_titles) == 0:\n",
    "                continue\n",
    "            pred_ratings = train_data[train_data['original_title'].isin(pred_titles)]['vote_average'].values\n",
    "            if len(pred_ratings) == 0:\n",
    "                continue\n",
    "            predictions.append((true_ratings.mean(), pred_ratings.mean()))\n",
    "    \n",
    "    # Filter out NaN values\n",
    "    predictions = [(true, pred) for true, pred in predictions if not np.isnan(pred)]\n",
    "    \n",
    "    if not predictions:\n",
    "        return float('nan'), float('nan')\n",
    "    \n",
    "    true_values, pred_values = zip(*predictions)\n",
    "    return mean_squared_error(true_values, pred_values), mean_absolute_error(true_values, pred_values)\n",
    "\n",
    "# Calculate MSE and MAE for the training data\n",
    "mse_train, mae_train = evaluate_model_train(train_data)\n",
    "print(f\"Mean Squared Error (Training): {mse_train}\")\n",
    "print(f\"Mean Absolute Error (Training): {mae_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch from 0 to 100\n",
      "Processing batch from 100 to 200\n",
      "Processing batch from 200 to 300\n",
      "Processing batch from 300 to 400\n",
      "Processing batch from 400 to 500\n",
      "Processing batch from 500 to 600\n",
      "Processing batch from 600 to 700\n",
      "Processing batch from 700 to 800\n",
      "Processing batch from 800 to 900\n",
      "Processing batch from 900 to 1000\n",
      "Training MSE: 2.3326603003281, MAE: 1.1929343495833729\n",
      "Test MSE: 2.2405352118303297, MAE: 1.2267159297928134\n"
     ]
    }
   ],
   "source": [
    "def compute_cosine_similarity_in_batches(matrix, batch_size=100):\n",
    "    n_items = matrix.shape[1]\n",
    "    sim_matrix = np.zeros((n_items, n_items))\n",
    "\n",
    "    for start in range(0, n_items, batch_size):\n",
    "        end = min(start + batch_size, n_items)\n",
    "        print(f\"Processing batch from {start} to {end}\")\n",
    "\n",
    "        batch_matrix = matrix[:, start:end].toarray()  # Convert only the batch to dense\n",
    "        batch_sim_matrix = cosine_similarity(batch_matrix.T)\n",
    "\n",
    "        # Place the batch similarity in the correct position in the full similarity matrix\n",
    "        sim_matrix[start:end, start:end] = batch_sim_matrix\n",
    "\n",
    "    return sim_matrix\n",
    "\n",
    "# Limit the dataset by selecting a subset of users and movies\n",
    "def limit_dataset(ratings, num_users=1000, num_movies=1000):\n",
    "    top_users = ratings['userId'].value_counts().head(num_users).index\n",
    "    top_movies = ratings['movieId'].value_counts().head(num_movies).index\n",
    "    limited_ratings = ratings[ratings['userId'].isin(top_users) & ratings['movieId'].isin(top_movies)]\n",
    "    return limited_ratings\n",
    "\n",
    "# Limit the dataset\n",
    "limited_ratings = limit_dataset(ratings, num_users=1000, num_movies=1000)\n",
    "\n",
    "# Create a pivot table\n",
    "ratings_matrix = limited_ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Convert the ratings matrix to a sparse matrix format\n",
    "ratings_sparse_matrix = csr_matrix(ratings_matrix.values)\n",
    "\n",
    "# Compute cosine similarity in batches for the sampled data\n",
    "cosine_sim_ratings = compute_cosine_similarity_in_batches(ratings_sparse_matrix)\n",
    "\n",
    "# Function to get collaborative filtering movie recommendations based on ratings\n",
    "def get_collaborative_recommendations(title, combined_data, cosine_sim_ratings, ratings_matrix):\n",
    "    if title not in combined_data['original_title'].values:\n",
    "        return f\"Movie '{title}' not found in the sampled data.\"\n",
    "    movie_id = combined_data[combined_data['original_title'] == title]['id'].values[0]\n",
    "    idx = ratings_matrix.columns.get_loc(movie_id)\n",
    "    sim_scores = list(enumerate(cosine_sim_ratings[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [ratings_matrix.columns[i[0]] for i in sim_scores]\n",
    "    return combined_data[combined_data['id'].isin(movie_indices)]['original_title']\n",
    "\n",
    "# Step 1: Split the data\n",
    "ratings_matrix = ratings_matrix.astype(np.float32)\n",
    "X_train, X_test = train_test_split(ratings_matrix, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Calculate user-user similarities\n",
    "def compute_user_similarity(matrix):\n",
    "    return cosine_similarity(matrix)\n",
    "\n",
    "train_similarities = compute_user_similarity(X_train)\n",
    "test_similarities = compute_user_similarity(X_test)\n",
    "\n",
    "# Function to predict ratings using collaborative filtering\n",
    "def predict_ratings(ratings_matrix, similarities, k=20):\n",
    "    pred = np.zeros(ratings_matrix.shape)\n",
    "    for i in range(ratings_matrix.shape[0]):\n",
    "        top_k_users = np.argsort(similarities[i])[-k:]\n",
    "        sim_sum = np.sum(np.abs(similarities[i, top_k_users]))\n",
    "        if sim_sum == 0:\n",
    "            continue  # Skip users with no similarities\n",
    "        for j in range(ratings_matrix.shape[1]):\n",
    "            pred[i, j] = similarities[i, top_k_users].dot(ratings_matrix[top_k_users, j])\n",
    "            pred[i, j] /= sim_sum\n",
    "    return pred\n",
    "\n",
    "# Step 3: Make predictions\n",
    "train_preds = predict_ratings(X_train.values, train_similarities)\n",
    "test_preds = predict_ratings(X_test.values, test_similarities)\n",
    "\n",
    "# Step 4: Compute evaluation metrics\n",
    "train_mse = mean_squared_error(X_train.values, train_preds)\n",
    "train_mae = mean_absolute_error(X_train.values, train_preds)\n",
    "\n",
    "test_mse = mean_squared_error(X_test.values, test_preds)\n",
    "test_mae = mean_absolute_error(X_test.values, test_preds)\n",
    "\n",
    "print(f\"Training MSE: {train_mse}, MAE: {train_mae}\")\n",
    "print(f\"Test MSE: {test_mse}, MAE: {test_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse mae calculation for hybrid approach\n",
    "\n",
    "sample_combined_data = combined_data.head(10000)  # Reduced from 20000 to 10000\n",
    "\n",
    "# Ensure the ratings dataset only includes ratings for the sampled movies\n",
    "sample_movie_ids = sample_combined_data['id'].tolist()\n",
    "sample_ratings = ratings[ratings['movieId'].isin(sample_movie_ids)]\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['revenue', 'budget', 'popularity', 'vote_average', 'vote_count', 'num_cast', 'num_keywords']\n",
    "sample_combined_data[numerical_features] = scaler.fit_transform(sample_combined_data[numerical_features])\n",
    "\n",
    "# Combine text features\n",
    "sample_combined_data['combined_features'] = (\n",
    "    sample_combined_data['overview'].fillna('') + \" \" +\n",
    "    sample_combined_data['genres'] + \" \" +\n",
    "    sample_combined_data['keywords'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    ")\n",
    "\n",
    "# Vectorize text data\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(sample_combined_data['combined_features'])\n",
    "\n",
    "# Compute content-based cosine similarity matrix\n",
    "cosine_sim_content = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Check for duplicates in ratings\n",
    "sample_ratings.drop_duplicates(subset=['userId', 'movieId'], inplace=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(sample_ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create user-item matrices for training and testing sets\n",
    "train_ratings_matrix = train_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "test_ratings_matrix = test_data.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Normalize ratings by subtracting the mean rating of each user in the training set\n",
    "train_ratings_matrix_normalized = train_ratings_matrix.sub(train_ratings_matrix.mean(axis=1), axis=0)\n",
    "\n",
    "# Convert the normalized ratings matrices to sparse matrices\n",
    "train_ratings_sparse_matrix = csr_matrix(train_ratings_matrix_normalized.values)\n",
    "\n",
    "# Function to compute cosine similarity in batches\n",
    "def compute_cosine_similarity_in_batches(matrix, batch_size=100):\n",
    "    n_items = matrix.shape[1]\n",
    "    sim_matrix = np.zeros((n_items, n_items))\n",
    "\n",
    "    for start in range(0, n_items, batch_size):\n",
    "        end = min(start + batch_size, n_items)\n",
    "        batch_matrix = matrix[:, start:end].toarray()\n",
    "        batch_sim_matrix = cosine_similarity(batch_matrix.T)\n",
    "        \n",
    "        sim_matrix[start:end, start:end] = batch_sim_matrix\n",
    "\n",
    "        for inner_start in range(0, start, batch_size):\n",
    "            inner_end = min(inner_start + batch_size, n_items)\n",
    "            inner_batch_matrix = matrix[:, inner_start:inner_end].toarray()\n",
    "            cross_sim_matrix = cosine_similarity(batch_matrix.T, inner_batch_matrix.T)\n",
    "            sim_matrix[start:end, inner_start:inner_end] = cross_sim_matrix\n",
    "            sim_matrix[inner_start:inner_end, start:end] = cross_sim_matrix.T\n",
    "\n",
    "    return sim_matrix\n",
    "\n",
    "# Compute cosine similarity in batches for the sampled data\n",
    "cosine_sim_ratings = compute_cosine_similarity_in_batches(train_ratings_sparse_matrix, batch_size=50)  # Adjusted batch size\n",
    "\n",
    "# Ensure the dimensions of cosine similarity matrices match\n",
    "min_dim = min(cosine_sim_content.shape[0], train_ratings_matrix.shape[1])\n",
    "cosine_sim_content = cosine_sim_content[:min_dim, :min_dim]\n",
    "cosine_sim_ratings = cosine_sim_ratings[:min_dim, :min_dim]\n",
    "\n",
    "# Normalize the similarity matrices\n",
    "cosine_sim_content_normalized = cosine_sim_content / np.max(cosine_sim_content)\n",
    "cosine_sim_ratings_normalized = cosine_sim_ratings / np.max(cosine_sim_ratings)\n",
    "\n",
    "# Combine similarity matrices with weights\n",
    "alpha = 0.5  # Weight for content-based filtering\n",
    "beta = 1 - alpha  # Weight for collaborative filtering\n",
    "combined_sim = alpha * cosine_sim_content_normalized + beta * cosine_sim_ratings_normalized\n",
    "\n",
    "# Predict ratings for the test set\n",
    "def predict_ratings_hybrid(user_id, movie_id, combined_sim, train_ratings_matrix):\n",
    "    if movie_id not in train_ratings_matrix.columns:\n",
    "        return 0  # Default rating if movie not in training set\n",
    "    movie_idx = train_ratings_matrix.columns.get_loc(movie_id)\n",
    "    user_idx = train_ratings_matrix.index.get_loc(user_id)\n",
    "    sim_scores = combined_sim[movie_idx]\n",
    "    user_ratings = train_ratings_matrix.iloc[user_idx]\n",
    "    weighted_sum = np.dot(sim_scores, user_ratings)\n",
    "    sum_of_weights = np.sum(sim_scores)\n",
    "    if sum_of_weights == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    predicted_rating = weighted_sum / sum_of_weights\n",
    "    return predicted_rating\n",
    "\n",
    "# Filter test data to include only movies in the training set\n",
    "train_movie_ids = set(train_ratings_matrix.columns)\n",
    "test_data_filtered = test_data[test_data['movieId'].isin(train_movie_ids)]\n",
    "\n",
    "# Apply predictions only to the filtered test data\n",
    "test_data_filtered['predicted_rating'] = test_data_filtered.apply(\n",
    "    lambda x: predict_ratings_hybrid(x['userId'], x['movieId'], combined_sim, train_ratings_matrix),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Compute MSE and MAE using the filtered test data\n",
    "mse = mean_squared_error(test_data_filtered['rating'], test_data_filtered['predicted_rating'])\n",
    "mae = mean_absolute_error(test_data_filtered['rating'], test_data_filtered['predicted_rating'])\n",
    "\n",
    "# print(\"MSE for hybrid recommendations:\", mse)\n",
    "# print(\"MAE for hybrid recommendations:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative Filtering Model w/ Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Content based does not have regularization like collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff942e538514c3491200ecd5fe8e3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Recommendations:\n",
      "('A Little Princess', 0.107552685)\n",
      "('Heat', 0.07591191)\n",
      "('Dunston Checks In', 0.07097376)\n",
      "('Legends of the Fall', 0.06286171)\n",
      "('Exotica', 0.05749233)\n",
      "('The Glass Shield', 0.056265943)\n",
      "('Balto', 0.04396431)\n",
      "('Bed of Roses', 0.03668877)\n",
      "('Just Cause', 0.034602586)\n",
      "(\"A Kid in King Arthur's Court\", 0.03280032)\n"
     ]
    }
   ],
   "source": [
    "#trying on downsized sample\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['revenue', 'budget', 'popularity', 'vote_average', 'vote_count', 'num_cast', 'num_keywords']\n",
    "sample_combined_data[numerical_features] = scaler.fit_transform(sample_combined_data[numerical_features])\n",
    "\n",
    "# Combine text features\n",
    "sample_combined_data['combined_features'] = sample_combined_data['overview'].fillna('') + \" \" + sample_combined_data['genres'] + \" \" + sample_combined_data['keywords'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "# Vectorize text data\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(sample_combined_data['combined_features'])\n",
    "\n",
    "cosine_sim_content = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Concatenate numerical features and TF-IDF features\n",
    "numerical_matrix = sample_combined_data[numerical_features].values\n",
    "combined_matrix = np.hstack([numerical_matrix, tfidf_matrix.toarray()])\n",
    "\n",
    "# Create the user-item matrix for the ratings\n",
    "ratings_matrix = sample_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "ratings_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# Convert ratings_matrix to a sparse matrix\n",
    "sparse_ratings_matrix = csr_matrix(ratings_matrix.values)\n",
    "\n",
    "# Train ALS model with regularization\n",
    "als_model = AlternatingLeastSquares(factors=100, regularization=0.1)\n",
    "als_model.fit(sparse_ratings_matrix)\n",
    "\n",
    "# Get item factors and user factors\n",
    "item_factors = als_model.item_factors\n",
    "user_factors = als_model.user_factors\n",
    "\n",
    "# Compute similarity between items using item factors\n",
    "item_similarity_matrix = cosine_similarity(item_factors)\n",
    "\n",
    "# Function to get item recommendations for a given item\n",
    "def get_item_recommendations(item_id, item_similarity_matrix=item_similarity_matrix, combined_data=sample_combined_data):\n",
    "    if item_id not in sample_combined_data['id'].values:\n",
    "        return f\"Item '{item_id}' not found in the data.\"\n",
    "    \n",
    "    item_idx = sample_combined_data[sample_combined_data['id'] == item_id].index[0]\n",
    "    \n",
    "    # Filter out invalid entries from the similarity matrix\n",
    "    sim_scores = [(idx, score) for idx, score in enumerate(item_similarity_matrix[item_idx]) if not np.isnan(score)]\n",
    "    \n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    recommended_items = []\n",
    "    for similar_item_idx, score in sim_scores:\n",
    "        if similar_item_idx != item_idx:\n",
    "            recommended_items.append((sample_combined_data['original_title'].iloc[similar_item_idx], score))\n",
    "            if len(recommended_items) >= 10:\n",
    "                break\n",
    "    \n",
    "    return recommended_items\n",
    "\n",
    "# Example usage for item recommendations\n",
    "item_id = 862 # Replace with an actual item ID from your data\n",
    "item_recommendations = get_item_recommendations(item_id)\n",
    "\n",
    "print(\"Item Recommendations:\")\n",
    "for item in item_recommendations:\n",
    "    print(f\"{item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Content based filtering so we can see what features of movies contribute to movie popularity\n",
    "- Although collaborative filtering allows us to determine how ratings influence movie popularity, content based also contains popularity and voting count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Intra-similarity): 0.24958866394386076\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "numerical_features = ['revenue', 'budget', 'popularity', 'vote_average', 'vote_count', 'num_cast', 'num_keywords']\n",
    "combined_data[numerical_features] = scaler.fit_transform(combined_data[numerical_features])\n",
    "\n",
    "# Combine text features\n",
    "combined_data['combined_features'] = combined_data['overview'].fillna('') + \" \" + combined_data['genres'] + \" \" + combined_data['keywords'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "# Vectorize text data\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(combined_data['combined_features'])\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get movie recommendations\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    idx = combined_data[combined_data['original_title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return combined_data['original_title'].iloc[movie_indices]\n",
    "\n",
    "def intra_similarity(recommended_movies, cosine_sim):\n",
    "    # Calculate cosine similarity matrix for the recommended movies\n",
    "    recommended_indices = [combined_data[combined_data['original_title'] == movie].index[0] for movie in recommended_movies]\n",
    "    recommended_cosine_sim = cosine_sim[recommended_indices][:, recommended_indices]\n",
    "    \n",
    "    # Compute average similarity among recommended movies\n",
    "    avg_similarity = np.mean(recommended_cosine_sim[np.triu_indices(len(recommended_movies), k=1)])\n",
    "    \n",
    "    return avg_similarity\n",
    "\n",
    "# Example usage\n",
    "recommended_movies = get_recommendations('Toy Story')\n",
    "accuracy = intra_similarity(recommended_movies, cosine_sim)\n",
    "print(\"Accuracy Score (Intra-similarity):\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy Score (Intra-similarity): 0.006864446227002278\n",
      "Recommendation System Accuracy Score (Intra-similarity): 0.24958866394386076\n"
     ]
    }
   ],
   "source": [
    "# Define a simple baseline method (e.g., recommending the most popular movies)\n",
    "def baseline_recommendation():\n",
    "    # Example: Recommend the top 10 most popular movies\n",
    "    popular_movies = combined_data['original_title'].value_counts().head(10).index.tolist()\n",
    "    return popular_movies\n",
    "\n",
    "# Evaluate the baseline method\n",
    "baseline_recommendations = baseline_recommendation()\n",
    "baseline_accuracy = intra_similarity(baseline_recommendations, cosine_sim)\n",
    "print(\"Baseline Accuracy Score (Intra-similarity):\", baseline_accuracy)\n",
    "\n",
    "# Evaluate the recommendation system\n",
    "recommended_movies = get_recommendations('Toy Story')\n",
    "system_accuracy = intra_similarity(recommended_movies, cosine_sim)\n",
    "print(\"Recommendation System Accuracy Score (Intra-similarity):\", system_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
